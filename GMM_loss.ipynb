{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CwX92Dgf3QZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992778b7-6974-43a9-b63b-bcf6e7c5cd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29431049.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# 데이터 준비\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "data_size = len(train_data)\n",
        "indices = np.arange(data_size)\n",
        "np.random.shuffle(indices)\n",
        "split = int(data_size * 0.9)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(indices[:split])\n",
        "valid_sampler = SubsetRandomSampler(indices[split:])\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "valid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GMMLoss(nn.Module):\n",
        "    def __init__(self, num_components, num_classes):\n",
        "        super(GMMLoss, self).__init__()\n",
        "        self.num_components = num_components\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, features, labels):\n",
        "        loss = 0\n",
        "        for c in range(self.num_classes):\n",
        "            class_features = features[labels == c]\n",
        "            if len(class_features) < self.num_components:  # 이 부분 추가\n",
        "                continue\n",
        "            gmm = GaussianMixture(n_components=self.num_components).fit(class_features.detach().cpu().numpy())\n",
        "            log_probabilities = gmm.score_samples(class_features.detach().cpu().numpy())\n",
        "            proba = torch.tensor(log_probabilities, dtype=torch.float32).to(features.device)\n",
        "\n",
        "            intra_gmm_distances = torch.mean(proba)\n",
        "\n",
        "            all_features_log_probs = torch.tensor(gmm.score_samples(features.detach().cpu().numpy()), dtype=torch.float32).to(features.device)\n",
        "            all_features_log_probs = torch.tensor(gmm.score_samples(features.detach().cpu().numpy()), dtype=torch.float32).to(features.device)\n",
        "            proba_all_features = all_features_log_probs\n",
        "            inter_gmm_distances = torch.mean(proba_all_features - proba.view(-1, 1))\n",
        "\n",
        "            loss += intra_gmm_distances - inter_gmm_distances\n",
        "\n",
        "        loss /= self.num_classes\n",
        "        return loss"
      ],
      "metadata": {
        "id": "ufrfDKkrxWEb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KAflhzsZ3TN1"
      },
      "outputs": [],
      "source": [
        "# 모델 정의\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        \n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SKGWJdbb3kN_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "f6db09c7-4c58-47c2-81ce-e5b9564c14d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 8991269.8149 Acc: 0.3857\n",
            "\n",
            "Epoch 1/5 - Val Loss: 887965.1637 Acc: 0.0537\n",
            "\n",
            "Epoch 2/5 - Train Loss: 9984119.3982 Acc: 0.5270\n",
            "\n",
            "Epoch 2/5 - Val Loss: 868092.8924 Acc: 0.0591\n",
            "\n",
            "Epoch 3/5 - Train Loss: 9701433.2014 Acc: 0.5871\n",
            "\n",
            "Epoch 3/5 - Val Loss: 848104.1409 Acc: 0.0698\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8d01eb52bdab>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 학습 및 검증\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 특징 추출 함수 정의\n",
        "def extract_intermediate_features(model, x):\n",
        "    x = model.conv_block1(x)\n",
        "    x = model.conv_block2(x)\n",
        "    x_return = model.conv_block3(x)  # 여기서 특징 추출\n",
        "    x = model.classifier(x_return.view(x_return.size(0), -1))\n",
        "    return x, x_return\n",
        "\n",
        "# 기본 손실 함수 및 GMM 손실 함수를 동시에 사용\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "gmm_loss = GMMLoss(num_components=5, num_classes=10)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 100\n",
        "\n",
        "best_loss = float('inf')  # 이 부분 추가\n",
        "for epoch in range(epochs):\n",
        "    # 학습 및 검증 코드\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            data_loader = train_loader\n",
        "            model.train()\n",
        "        else:\n",
        "            data_loader = valid_loader\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        corrects = 0\n",
        "\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs, features = extract_intermediate_features(model, inputs)  # 바뀐 부분\n",
        "                loss = criterion(outputs, labels) + gmm_loss(features.mean([2, 3]), labels)  # GMM 손실 함수 추가\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(data_loader.dataset)\n",
        "        epoch_acc = corrects.double() / len(data_loader.dataset)\n",
        "\n",
        "        if phase == 'train':\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "            if epoch > 10:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = 0.0005\n",
        "            if epoch > 20:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = 0.0001\n",
        "            if epoch > 30:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = 0.00005\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "            if epoch_loss < best_loss:\n",
        "                torch.save(model.state_dict(), 'best_cnn_model.pt')\n",
        "                best_loss = epoch_loss\n",
        "        print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}